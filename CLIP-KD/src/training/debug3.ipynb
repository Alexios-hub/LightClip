{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RN50', 'openai'),\n",
       " ('RN50', 'yfcc15m'),\n",
       " ('RN50', 'cc12m'),\n",
       " ('RN50-quickgelu', 'openai'),\n",
       " ('RN50-quickgelu', 'yfcc15m'),\n",
       " ('RN50-quickgelu', 'cc12m'),\n",
       " ('RN101', 'openai'),\n",
       " ('RN101', 'yfcc15m'),\n",
       " ('RN101-quickgelu', 'openai'),\n",
       " ('RN101-quickgelu', 'yfcc15m'),\n",
       " ('RN50x4', 'openai'),\n",
       " ('RN50x16', 'openai'),\n",
       " ('RN50x64', 'openai'),\n",
       " ('ViT-B-32', 'openai'),\n",
       " ('ViT-B-32', 'laion400m_e31'),\n",
       " ('ViT-B-32', 'laion400m_e32'),\n",
       " ('ViT-B-32', 'laion2b_e16'),\n",
       " ('ViT-B-32', 'laion2b_s34b_b79k'),\n",
       " ('ViT-B-32', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n",
       " ('ViT-B-32-256', 'datacomp_s34b_b86k'),\n",
       " ('ViT-B-32-quickgelu', 'openai'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e31'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e32'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16', 'openai'),\n",
       " ('ViT-B-16', 'laion400m_e31'),\n",
       " ('ViT-B-16', 'laion400m_e32'),\n",
       " ('ViT-B-16', 'laion2b_s34b_b88k'),\n",
       " ('ViT-B-16', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'dfn2b'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e31'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'openai'),\n",
       " ('ViT-L-14', 'laion400m_e31'),\n",
       " ('ViT-L-14', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'laion2b_s32b_b82k'),\n",
       " ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-L-14-quickgelu', 'dfn2b'),\n",
       " ('ViT-L-14-336', 'openai'),\n",
       " ('ViT-H-14', 'laion2b_s32b_b79k'),\n",
       " ('ViT-H-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-H-14-quickgelu', 'dfn5b'),\n",
       " ('ViT-H-14-378-quickgelu', 'dfn5b'),\n",
       " ('ViT-g-14', 'laion2b_s12b_b42k'),\n",
       " ('ViT-g-14', 'laion2b_s34b_b88k'),\n",
       " ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n",
       " ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n",
       " ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n",
       " ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n",
       " ('convnext_base', 'laion400m_s13b_b51k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n",
       " ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n",
       " ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n",
       " ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('EVA01-g-14', 'laion400m_s11b_b41k'),\n",
       " ('EVA01-g-14-plus', 'merged2b_s11b_b114k'),\n",
       " ('EVA02-B-16', 'merged2b_s8b_b131k'),\n",
       " ('EVA02-L-14', 'merged2b_s4b_b131k'),\n",
       " ('EVA02-L-14-336', 'merged2b_s6b_b61k'),\n",
       " ('EVA02-E-14', 'laion2b_s4b_b115k'),\n",
       " ('EVA02-E-14-plus', 'laion2b_s9b_b144k'),\n",
       " ('ViT-B-16-SigLIP', 'webli'),\n",
       " ('ViT-B-16-SigLIP-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-i18n-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-384', 'webli'),\n",
       " ('ViT-B-16-SigLIP-512', 'webli'),\n",
       " ('ViT-L-16-SigLIP-256', 'webli'),\n",
       " ('ViT-L-16-SigLIP-384', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP-384', 'webli'),\n",
       " ('ViT-L-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-L-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA-336', 'laion2b'),\n",
       " ('ViT-H-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA-336', 'datacomp1b'),\n",
       " ('nllb-clip-base', 'v1'),\n",
       " ('nllb-clip-large', 'v1'),\n",
       " ('nllb-clip-base-siglip', 'v1'),\n",
       " ('nllb-clip-large-siglip', 'v1')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open_clip\n",
    "open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor = torch.load('/home/user/data/cc12m_dr/00000/000000000.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_emb': [tensor([ 0.1157,  1.2656, -0.2930,  ..., -0.4492, -0.3359,  1.3516],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([0.0024, 1.0938, 0.7031,  ..., 0.2285, 0.5234, 0.6055],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.1738,  1.5781,  0.3359,  ..., -0.0427,  0.5664,  0.6289],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.4258,  0.8086, -0.2412,  ..., -0.0287, -0.5000,  0.4570],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.2910,  0.7891,  0.1035,  ..., -0.6445,  0.1064,  0.9688],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.1299,  1.3438,  0.0114,  ..., -0.5625,  0.6484,  1.0078],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0298,  0.9766, -0.1768,  ..., -0.1504, -0.4902,  1.3047],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.1445,  0.8555,  0.0933,  ..., -0.2676, -0.5352,  0.6680],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.3789,  1.3594,  0.3340,  ..., -0.2559, -0.6367,  1.0703],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.3398,  1.1953, -0.3281,  ..., -0.1572, -0.1943,  1.5391],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0150,  1.0625, -0.4062,  ..., -0.2422, -0.2256,  0.8281],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.1475,  0.9297,  0.2432,  ..., -0.4707,  0.7891,  0.8711],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0566,  0.9141,  0.1035,  ..., -0.7422, -0.0289,  1.5312],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.2344,  0.8516,  0.1836,  ..., -0.4043,  0.4102,  0.7617],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0120,  1.5703, -0.0664,  ..., -0.6289,  0.0942,  0.7539],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 1.5503e-02,  6.0547e-01, -1.1377e-01,  ..., -6.1719e-01,\n",
       "          -7.5340e-05,  1.3359e+00], dtype=torch.bfloat16),\n",
       "  tensor([-0.0884,  1.0859,  0.1416,  ...,  0.0210, -0.2100,  0.4531],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.2393,  1.0938,  0.2832,  ..., -0.1504, -0.6992,  0.6289],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0537,  1.4531,  0.0439,  ..., -0.0040,  0.1270,  0.9688],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.0275,  1.3047, -0.0693,  ..., -0.0223, -1.1328,  0.9453],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.1113,  0.9492,  0.0408,  ..., -0.1025,  0.1245,  0.9492],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.2314,  0.8906,  0.8047,  ..., -0.4219, -0.9805,  1.2188],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0610,  0.9219,  0.3730,  ..., -0.3418,  0.5273,  1.2734],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0503,  1.5391, -0.1484,  ..., -0.6719, -0.1904,  0.6562],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.2158,  0.9375,  0.3887,  ..., -0.0500, -0.7852,  0.9375],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.1787,  0.8906, -0.2080,  ...,  0.1084,  0.5117,  0.9766],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0664,  0.8711,  0.0261,  ...,  0.0549, -0.6641,  1.0703],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.3457,  0.5938,  0.3887,  ..., -0.2373,  0.3047,  1.0156],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([0.1426, 1.4219, 0.5078,  ..., 0.0156, 0.1201, 0.9570],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.1777,  0.9336,  0.1377,  ..., -0.1602,  0.2070,  0.6289],\n",
       "         dtype=torch.bfloat16)],\n",
       " 'text_emb': [tensor([ 0.2773,  0.3105, -0.1572,  ..., -0.4414, -1.0234,  0.6680],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.0518,  0.3379, -0.1270,  ...,  0.5156,  0.8828, -0.8398],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([ 0.6211, -0.1348, -0.1514,  ..., -0.3125, -0.0130,  0.4355],\n",
       "         dtype=torch.bfloat16),\n",
       "  tensor([-0.4141,  0.0559,  0.5078,  ..., -0.4258,  1.6562,  0.5547],\n",
       "         dtype=torch.bfloat16)]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor['image_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['image_emb'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor['text_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['text_emb'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/user/data/DataCompDR/DataCompDR-12M-bf16/00000000/5252820736bc680b29c6dca972776dc3.paug.json','r') as f:\n",
    "    dic = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(dic['param_aug']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(dic['param_aug'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33, 29, 48, 57], [[13, 0.0], [11, 178.5]]]\n"
     ]
    }
   ],
   "source": [
    "print(dic['param_aug'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import torch\n",
    "\n",
    "with gzip.open('/home/user/data/DataCompDR/DataCompDR-12M-bf16/00000000/5252820736bc680b29c6dca972776dc3.pth.gz', 'rb') as f:\n",
    "    tensor = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(tensor['text_emb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "print(tensor['text_emb'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "print(tensor['image_emb'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0037, -0.0552, -0.0244,  ..., -0.0537, -0.0037,  0.0378],\n",
       "        [ 0.0037, -0.0552, -0.0244,  ..., -0.0537, -0.0037,  0.0378],\n",
       "        [ 0.0408, -0.0261,  0.0214,  ..., -0.0776, -0.0013, -0.0064],\n",
       "        ...,\n",
       "        [-0.0272, -0.0254,  0.0016,  ..., -0.0479,  0.0339,  0.0535],\n",
       "        [-0.0109,  0.0195,  0.0005,  ..., -0.0520, -0.0298,  0.0072],\n",
       "        [-0.0186, -0.0315, -0.0067,  ..., -0.0737,  0.0508,  0.0366]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['text_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0037, -0.0552, -0.0244,  ..., -0.0537, -0.0037,  0.0378],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['text_emb'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0037, -0.0552, -0.0244,  ..., -0.0537, -0.0037,  0.0378],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['text_emb'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0408, -0.0261,  0.0214,  ..., -0.0776, -0.0013, -0.0064],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['text_emb'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor['text_emb'][0] == tensor['text_emb'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (tensor['text_emb'][0] == tensor['text_emb'][1]):\n",
    "    if i == True:\n",
    "        continue\n",
    "    else:\n",
    "        print(False)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5859, dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(tensor['text_emb'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.nn.functional.normalize(tensor['text_emb'][0],dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
